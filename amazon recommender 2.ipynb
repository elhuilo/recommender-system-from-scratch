{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a9830d7b9dbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame \n",
    "import nltk\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean = pd.read_csv('documents/2019-05/Recommender System/df_clean without index.csv')\n",
    "n_users = df_clean.userID.unique().shape[0]\n",
    "n_items = df_clean.itemID.unique().shape[0]\n",
    "count = df_clean.groupby(\"itemID\", as_index=False).mean()\n",
    "count_users = df_clean.groupby(\"userID\", as_index=False).count()\n",
    "count_users.loc[count_users['userID'] == '0013000000Eqrg2AAB']\n",
    "items_df = count[['itemID']]\n",
    "users_df = count_users[['userID']]\n",
    "users_list = users_df.values\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainSet, testSet = train_test_split(df_clean, test_size=0.2,stratify=df_clean['userID'])\n",
    "mean_items = trainSet.groupby(['itemID']).mean()\n",
    "mean_users = trainSet.groupby(['userID']).mean()\n",
    "mean_overall = trainSet[\"rating\"].mean() \n",
    "train_data_matrix_na = trainSet.pivot_table(index='itemID', columns='userID', values='rating').fillna(0)\n",
    "train_data_matrix = train_data_matrix_na\n",
    "train_data_matrix = train_data_matrix.loc[:, (train_data_matrix != 0).any(axis=0)]\n",
    "train_data_matrix = train_data_matrix.loc[(train_data_matrix != 0).any(axis=1), :]\n",
    "from scipy.spatial.distance import correlation\n",
    "neighbor = NearestNeighbors(n_neighbors=4, algorithm='auto', metric = 'cosine').fit(train_data_matrix)\n",
    "distances, indices = neighbor.kneighbors(train_data_matrix)\n",
    "\n",
    "\n",
    "reference_index = train_data_matrix.index.values\n",
    "reference_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('documents/2019-05/Recommender System/df_clean without index.csv')\n",
    "pivot_categorized = df_clean.pivot_table(index='itemID', columns='userID', values='rating').fillna(0)\n",
    "pivot_categorized = pivot_categorized.loc[:, (pivot_categorized != 0).any(axis=0)]\n",
    "pivot_categorized = pivot_categorized.loc[(pivot_categorized != 0).any(axis=1), :]\n",
    "pivot_categorized.to_csv('documents/2019-05/Recommender System/pivot_categorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating = {}\n",
    "\n",
    "line = testSet.values[0]\n",
    "myuser = line[1]\n",
    "myitem = line[0]\n",
    "myrate = line[2]\n",
    "its_location, =np.where(reference_index == myitem)\n",
    "its_location = its_location[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "[0.         0.65627379 0.67031249 0.80057925]\n",
      "[498 768 146 812]\n",
      "____________________________________\n"
     ]
    }
   ],
   "source": [
    "myitem_distances = distances[its_location:its_location+1][0]\n",
    "myitem_indices = indices[its_location:its_location+1][0]\n",
    " \n",
    "bi = mean_items.loc[myitem]['rating'] - mean_overall\n",
    "bx = mean_users.loc[myuser]['rating'] - mean_overall\n",
    "bxi = mean_overall + bi + bx\n",
    "\n",
    "print(its_location)\n",
    "print(myitem_distances)\n",
    "print(myitem_indices)\n",
    "\n",
    "print(\"____________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating = {}\n",
    "\n",
    "for line in testSet.values[1:20]:\n",
    "    myuser = line[1]\n",
    "    myitem = line[0]\n",
    "    myrate = line[2]\n",
    "# myuser = 'AMCAID3LTHKEC'   #testSet[1:4]['reviewerID'].iat[0]\n",
    "# myitem = 'B00007LVCN'  #testSet[5:6]['asin'].iat[0]\n",
    "\n",
    "    its_location, =np.where(reference_index == myitem)\n",
    "    its_location = its_location[0]\n",
    "\n",
    "    myitem_distances = distances[its_location:its_location+1][0]\n",
    "    myitem_indices = indices[its_location:its_location+1][0]\n",
    "    \n",
    "    bi = mean_items.loc[myitem]['rating'] - mean_overall\n",
    "    bx = mean_users.loc[myuser]['rating'] - mean_overall\n",
    "    bxi = mean_overall + bi + bx\n",
    "    \n",
    "    \n",
    "    item_occurences_in_train = []\n",
    "    for i in range(4):\n",
    "        item_occurence = trainSet.loc[(trainSet['itemID'] == reference_index[myitem_indices[i]]) & (trainSet['userID'] == myuser)]\n",
    "        bi_n = mean_items.loc[reference_index[myitem_indices[i]]]['rating'] - mean_overall\n",
    "        bix_n = mean_overall + bi_n + bx\n",
    "        item_occurences_in_train.append((item_occurence, myitem_distances[i], bix_n))\n",
    "    sim_rating = 0\n",
    "\n",
    "    for line in item_occurences_in_train:\n",
    "        if not line[0].empty:\n",
    "            sim_rating = sim_rating + (line[0]['rating'].values-line[2])*(line[1])\n",
    "            sim_rating=sim_rating[0]\n",
    "\n",
    "    pred = bxi + sim_rating\n",
    "    pred_rating[(myitem, myuser, myrate)] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908.469035887094\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for key in pred_rating:\n",
    "    y_true.append(key[2])\n",
    "    y_pred.append(pred_rating[key])\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_true, y_pred, multioutput='uniform_average')\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame \n",
    "import nltk\n",
    "import random\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gl.factorization_recommender.create(sf_train, target=\"rating\")\n",
    "model.predict(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
