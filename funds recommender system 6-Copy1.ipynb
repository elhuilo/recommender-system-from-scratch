{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "data = pd.read_csv('weights.csv')\n",
    "WT = pd.read_csv('wisdomtree.csv')\n",
    "WT = list(WT['Ticker'])\n",
    "#df to pivot table\n",
    "#matrix = df.pivot_table(index = 'user_id', columns ='item_id', values ='rating')\n",
    "matrix = data.pivot_table(index = 'Account__c', columns ='Ticker__c', values ='AUM_weight')\n",
    "data = matrix.fillna(0)\n",
    "#drop columns that are all zero\n",
    "data = data.loc[:, (data != 0).any(axis=0)]\n",
    "data.insert(0, 'user', range(0, 0 + len(data)))\n",
    "data_items = data.drop('user', axis =1)\n",
    "#data.to_csv(r'documents/2019-04/New Fund/data_matrix2.csv')\n",
    "\n",
    "\n",
    "\"\"\"ITEM TO ITEM CALCULATION\"\"\"\n",
    "# normalize user vectors to unit vectors\n",
    "# magnitude = sqrt(x2 + y2 + z2 + ...)\n",
    "#magnitude = np.sqrt(np.square(data_items).sum(axis=1))\n",
    "# unit vector = (x / magnitude, y / magnitude, z/ magnitude ...)\n",
    "#data_items = data_items.divide(magnitude, axis = 'index')\n",
    "#data_items.to_csv(r'documents/2019-04/New Fund/data_items2.csv')\n",
    "\n",
    "\"\"\"build function: calculate the column-wise cosine similarity and store into new df\"\"\"\n",
    "def calculate_similarity(data_items):\n",
    "    #\"store matrix into sparse format\"\n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    \"\"\"transpose the df since cos sim function only works for rows and find similarities\"\"\"\n",
    "    similarities = cosine_similarity(data_sparse.transpose()) \n",
    "    \"\"\"store into dataframe\"\"\"\n",
    "    sim = pd.DataFrame(data = similarities, index= data_items.columns, columns= data_items.columns)\n",
    "    return sim\n",
    "\n",
    "\"\"\"cosine similairty matrix\"\"\"\n",
    "data_matrix2 = calculate_similarity(data_items)\n",
    "\n",
    "\"\"\"only keep wisdomtree columns in matrix\"\"\"\n",
    "wisdomtree_list = []\n",
    "for col in list(data_matrix2.columns.values):\n",
    "    if col in WT:\n",
    "        wisdomtree_list.append(col)\n",
    "data_matrix = data_matrix2[wisdomtree_list]\n",
    "\n",
    "\"\"\"USER TO ITEM CALCULATION\n",
    "new dataframe with k closest neighbours (most similar) for each ticker\"\"\"\n",
    "\n",
    "\"\"\"create columns for top 6 recommendations\"\"\"\n",
    "data_neighbours = pd.DataFrame(index=data_matrix.index, columns=range(1,7))\n",
    "\n",
    "for i in range(0, len(data_matrix.index)):\n",
    "    \"\"\"\"the neighbours = selecting the column and choosing the top 5\"\"\"\n",
    "    \"\"\"i is the column number for the ticker\"\"\"\n",
    "    #note: column 1, 2, 3 in csv = index 0, 1, 2\n",
    "    data_neighbours.iloc[i,:6] = data_matrix.iloc[i, 0:].sort_values(ascending=False)[:6].index\n",
    "\n",
    "#make new blank column in original data frame for each user's recommendation \n",
    "data['bought tickers'] = \"\"\n",
    "data['recommendation'] = \"\"\n",
    "#data_matrix.to_csv(r'documents/2019-04/New Fund/data_matrix2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['user']:\n",
    "    user = int(i)\n",
    "    \"\"\"get user ID\"\"\"\n",
    "    user_index = data[data.user == user].index.tolist()[0]\n",
    "    \"\"\"Get the tickers the user bought before\"\"\"\n",
    "    known_user_likes = data_items.loc[user_index] #gets the row in matrix according to account ID\n",
    "    known_user_likes = known_user_likes[known_user_likes >0].index.values #keep only the bought tickers\n",
    "    \n",
    "    \"\"\"construct neighbourhood of tickers similar to ones already bought\"\"\"\n",
    "    \"\"\"data frame of top 6 most similar items to each bought item\"\"\"\n",
    "    most_similar_to_likes = data_neighbours.loc[known_user_likes]\n",
    "    #make list of all similar tickers into a list\n",
    "    similar_list2 = most_similar_to_likes.values.tolist()\n",
    "    \"\"\"orders are not correct, need to append bought tickers to list\"\"\"\n",
    "    \"\"\"question: top 20 tickers instead?\"\"\"\n",
    "    most_similar_to_likes_col = most_similar_to_likes.index.tolist()\n",
    "    similar_list2.append(most_similar_to_likes_col)\n",
    "\n",
    "    #make lists in list into a flat list, and dedupe \n",
    "    similar_list = []\n",
    "    for sublist in similar_list2:\n",
    "        for item in sublist:\n",
    "            similar_list.append(item)\n",
    "    similar_list = list(dict.fromkeys(similar_list))\n",
    "    \n",
    "    #make matrix of similarities between similar items\n",
    "    neighbourhood = data_matrix2[similar_list].loc[similar_list]\n",
    "    # user weights for each item neighbourhood and item bought before \n",
    "    user_vector = data_items.loc[user_index].loc[similar_list]\n",
    "    \"\"\"Calculate the score using formula\"\"\"\n",
    "    \"\"\"REEVALUATE SCORE METHOD\"\"\"\n",
    "    #(dot product of neighbourhood and user rating)/sum of neighbourhood\n",
    "    score2 = neighbourhood.dot(user_vector).div(neighbourhood.sum(axis=1))\n",
    "    # Drop the tickers bought before \n",
    "    \n",
    "    score = score2.drop(known_user_likes)\n",
    "    top5 = score.nlargest(5)\n",
    "    #top5df =pd.DataFrame({'tickers':top5.index, 'score':top5.values})\n",
    "    data.iloc[user, data.columns.get_loc('bought tickers')] = str(known_user_likes)\n",
    "    data.iloc[user, data.columns.get_loc('recommendation')] = str(top5.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data[['user','bought tickers', 'recommendation']]\n",
    "df1.to_csv('finaldf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
