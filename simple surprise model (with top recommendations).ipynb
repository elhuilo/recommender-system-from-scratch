{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import surprise\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Dataset, evaluate\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import SlopeOne\n",
    "from surprise import NMF\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBaseline\n",
    "from surprise import KNNBasic \n",
    "from surprise import KNNWithZScore \n",
    "from surprise import BaselineOnly\n",
    "from surprise import CoClustering\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('ratings data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ratings data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(data[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True\n",
    "}\n",
    " \n",
    "knn = KNNWithZScore (sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn.train(trainingSet)\n",
    "#testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "#predictions = knn.test(testset)\n",
    "predictions = knn.fit(trainset).test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9851451199247727"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "RMSE: 0.9848\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.9853\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.9853\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.9856\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.9851\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "#algo = KNNWithZScore()\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset = data.build_full_trainset()\n",
    "#algo = SVD()\n",
    "#algo.train(trainset)\n",
    "#testset = data.construct_testset(raw_testset=data.raw_ratings)\n",
    "#predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_top_k(predictions, k):\n",
    "    '''Return a top_k dicts where keys are user ids and values are lists of\n",
    "    tuples [(item id, rating estimation) ...].\n",
    "\n",
    "    Takes in a list of predictions as returned by the test method.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_k = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_k[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_k.items():\n",
    "        user_ratings.sort(key=lambda x:x[1], reverse=True)\n",
    "        top_k[uid] = user_ratings[:k]\n",
    "\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = get_top_k(predictions, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the recommended items\n",
    "for uid, user_ratings in top_k.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])\n",
    "# Compute the total number of recommended items.\n",
    "all_recommended_items = set(iid for (_, user_ratings) in top_k.items() for\n",
    "                            (iid, _) in user_ratings)\n",
    "#print('Number of recommended items:', len(all_recommended_items), 'over',\n",
    "      #len(top_k), 'users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
